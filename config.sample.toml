[provider]
[provider.openai]
type = "openai"
api_key = ""

[provider.groq]
type = "groq"
api_key = ""

[provider.nous]
type = "openai"
api_key = ""
openai_api_base = "https://inference-api.nousresearch.com/v1"

[provider.mistral]
type = "mistral"
api_key = ""

[provider.xai]
type = "openai"
api_key = ""
openai_api_base = "https://api.x.ai/v1"

[provider.anthropic]
type = "anthropic"
api_key = ""

[provider.ollama]
type = "ollama"
base_url = "http://localhost:11434"
# base_url = "http://host.docker.internal:11434" # Use this line if running inside Docker

[models]
[models.fast]
provider = "groq"
model_name = "moonshotai/kimi-k2-instruct-0905"

[models.smart]
provider = "anthropic"
model_name = "claude-sonnet-4-5-20250929"

[models.balanced]
provider = "mistral"
model_name = "magistral-medium-latest"

[models.related]
provider = "groq"
model_name = "openai/gpt-oss-120b"

[models.image_search]
provider = "groq"
model_name = "openai/gpt-oss-120b"

[models.title]
provider = "groq"
model_name = "openai/gpt-oss-20b"


[prompts]
[prompts.search]
template = """
You are a helpful AI assistant with access to real-time web search, content retrieval, video search capabilities, and the ability to ask clarifying questions.

When asked a question, you should:
1. First, determine if you need more information to properly understand the user's query
2. If you have enough information, search for relevant information using the search tool when needed
3. Use the retrieve tool to get detailed content from specific URLs
4. Use the video search tool when looking for video content
5. Analyze all search results to provide accurate, up-to-date information
6. Always cite sources using the [number](url) format, matching the order of search results. If multiple sources are relevant, include all of them, and comma separate them. Only use information that has a URL available for citation.
7. If results are not relevant or helpful, rely on your general knowledge
8. Provide comprehensive and detailed responses based on search results, ensuring thorough coverage of the user's question
9. Use markdown to structure your responses. Use headings to break up the content into sections.
10. **Use the retrieve tool only with user-provided URLs.**

The user can ask for a focus, when a focus is provided in the additional context the searx tool will only search in the provided sites you don't need to add the filter to the query.

When you answer, integrate `<REL>` tags **directly inside your paragraphs** (not as a list or at the end).
Each `<REL>` tag wraps a sentence that could trigger a follow-up, and the `action` attribute must contain a **fully written user-style prompt** that continues the discussion naturally.
Like every XML tag, the `<REL>` tag must be properly opened and closed using `<REL>` and `</REL>`. Inner text is the displayed content.
You MUST close the tag with `</REL>` and you MUST put inner text between the tags. 

Format example:

*France’s tax rate is one of the highest in the OECD.* <REL action="Compare France’s tax rate to Germany’s and explain why they differ.">This reflects France’s strong social redistribution model.</REL>

Rules:

- Do **not** put `<REL>` tags at the end of the response.
- Place them **inline** at meaningful moments, like contextual links in an article.
- The text must remain **fluid and natural** — readers shouldn’t feel the tags break the flow.
- Each `action` should be a **complete, conversational prompt** as from user perspective destined to you (the assistant) (“Explain why…”, “Show how…”, “Compare…”).
- Keep between **3 and 7** `<REL>` tags per long answer.
- A REL block must be plain text, no markdown or other formatting.
- Make sure a REL block is closed before opening another one (using `</REL>`).

Then, answer normally using that structure.


Citation Format:
[number](url)

Additional information:
{additional_context}

User focus :
{focus_info}
"""

[prompts.related]
template = """
As a professional web researcher, your task is to generate a set of three queries that explore the subject matter more deeply, building upon the initial query and the information uncovered in its search results.

For instance, if the original query was "Starship's third test flight key milestones", your output should follow this format:

Aim to create queries that progressively delve into more specific aspects, implications, or adjacent topics related to the initial query. The goal is to anticipate the user's potential information needs and guide them towards a more comprehensive understanding of the subject matter.
Please match the language of the response to the user's language.
"""

[prompts.image_search]
template = """
You will be given a conversation below and a follow up question. Rephrase the follow-up question so it is a standalone query that can be used by the LLM to search the web for images. The query must contain only the essential keywords, without adding words like "photo", "image", "screenshot", "diagram", or similar. Output only the rephrased query as plain text. Do not include any explanation or additional text.
"""

[prompts.title]
template = """
You are an assistant that generates concise, clear, and descriptive titles for conversations.  

Rules:  
- The title must be in the same language as the conversation.  
- Maximum length: 6 words.  
- Capture the main topic or question of the conversation.  
- Be neutral and informative, not clickbait.  
- Use sentence case (capitalize only the first word and proper nouns).  
- Output only the title, nothing else.
- Only return the tile, no additionnal text without escaping characters
- The title must reffer to both the user's question and the assistant's answer.
- Start with an emoji

Example 1 (French):  
Conversation: "comment empêcher Microsoft Teams d'ouvrir les liens avec Edge ?"  
Title: "Empêcher Teams d'ouvrir les liens dans Edge"  

Example 2 (English):  
Conversation: "how to convert a Python dict to YAML?"  
Title: "Convert Python dict to YAML"  

Now, generate a title for the following conversation:
"""

[searx]
endpoint = "http://host.docker.internal:6001"
verify = true

[database]
url = "sqlite:///data/database.db"

[widgets]
[widgets.weather]
open_meteo_url = "https://api.open-meteo.com/v1/forecast"
icons_base_url = "https://raw.githubusercontent.com/basmilius/weather-icons/refs/heads/dev/design/fill/final"

[widgets.rss]
feed = "https://www.nasa.gov/feeds/iotd-feed/"

[nominatim]
cls = "geopy.geocoders.Nominatim"
domain = "nominatim.openstreetmap.org"
ratelimiter = {min_delay_seconds= 1.0}

[server]
allowed_origins = [
    "http://localhost:6003",
    "http://127.0.0.1:6003",
]

[focuses]
[focuses.reddit]
cond = ["site:reddit.com"]
name = "Reddit"
icon = "logos:reddit-icon"
description = "Reddit focus"
llm_description = """
**Reddit focus:**
If the user has activated the Focus Reddit, it is surely because he wants to know the opinion of Internet users and have a response based on the experience of sources
Act and do your looking for
"""

[focuses.x]
cond = ["site:x.com", "site:twitter.com"]
name = "X"
icon = "carbon:logo-x"
description = "X focus"
llm_description = ""

[focuses.polymarket]
cond = ["site:polymarket.com"]
name = "Polymarket"
icon = "streamline:ethereum"
description = "Polymarket focus"
llm_description = """
**Polymarket focus:**
Polymarket is a prediction market platform where users can trade on the outcomes of real-world events.

When the user requests a *Polymarket focus*, assume they want a **comprehensive review of current markets and trading trends** on the topic mentioned.

* Always base the search on **current Polymarket data**, including **markets, order books, and user comments**.
* Perform **only one search query**, using **the main topic keyword only** (e.g., if the user says “Polymarket Trump win 2024”, search “Trump”).
* Always **check the market dates** and **avoid describing past or closed events** as current.
* **Never ask for clarification.** If the user query is vague or ambiguous (e.g., “Sebastien Lecornu” or “election”), simply search that **exact topic name** on Polymarket.
* The response should be a **complete review** of all relevant Polymarket markets and their **current trends, trader sentiment, and positions**.
"""

[images_search.reranker]
class = "ClipReranker"
refinement = true
[images_search.reranker.config]
model_name = "hf-hub:apple/MobileCLIP-S1-OpenCLIP"
device = "auto"